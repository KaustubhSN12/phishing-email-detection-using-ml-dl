{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asH5IImWuqVK"
   },
   "source": [
    "##PART 1 DONT RUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfssHigGoFYc"
   },
   "source": [
    "Installation of Streamlit pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11194,
     "status": "ok",
     "timestamp": 1760195915256,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "O7b_zdznfmAx",
    "outputId": "ec2666a3-8eb5-4d0e-fc5d-dcda229ceca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
      "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.7.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
      "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyngrok-7.4.0-py3-none-any.whl (25 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyngrok, pydeck, streamlit\n",
      "Successfully installed pydeck-0.9.1 pyngrok-7.4.0 streamlit-1.50.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install streamlit pyngrok pandas matplotlib joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNeG1mm1geXt"
   },
   "outputs": [],
   "source": [
    "#Runtime â†’ Restart runtime â†’ Yes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRlStUn0gBOH"
   },
   "source": [
    "#Streamlit\n",
    "\n",
    "https://dashboard.ngrok.com/get-started/your-authtoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWeLrugPhh8-"
   },
   "source": [
    "Incase of error run below codes to restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1760195927293,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "US_90tIzhiN9"
   },
   "outputs": [],
   "source": [
    "!pkill streamlit\n",
    "!pkill ngrok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1760195930945,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "x74V2vQ2hlYK"
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "ngrok.kill()  # ensures all tunnels are closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1370,
     "status": "ok",
     "timestamp": 1760195934964,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "3H0r05jonro-",
    "outputId": "32993e04-262f-4a14-aa81-d31cd3630a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!ngrok config add-authtoken Your-Grok-APIKEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBSrlHTwpMiY"
   },
   "source": [
    "### APP backup code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1759907587296,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "1HwLu6zif5hT",
    "outputId": "60e3c739-39de-4124-ed52-963a70ab66ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "# # ===============================================\n",
    "# # app.py - Email Phishing Detection Streamlit App\n",
    "# # ===============================================\n",
    "# %%writefile app.py\n",
    "# # your code here\n",
    "\n",
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import joblib\n",
    "# import re\n",
    "\n",
    "# # ------------------------------\n",
    "# # Page Configuration\n",
    "# # ------------------------------\n",
    "# st.set_page_config(page_title=\"Email Phishing Detection System\", layout=\"wide\")\n",
    "# st.title(\"ðŸ“§ Email Phishing Detection System\")\n",
    "# st.markdown(\"\"\"\n",
    "# This interactive app detects whether an email is **Phishing** or **Legitimate** based on its content.\n",
    "# It uses text analysis and machine learning for cybersecurity awareness and prevention.\n",
    "# \"\"\")\n",
    "\n",
    "# # ------------------------------\n",
    "# # Load Dataset\n",
    "# # ------------------------------\n",
    "# st.header(\"ðŸ“ Dataset Overview\")\n",
    "\n",
    "# df = None # Initialize df to None\n",
    "# try:\n",
    "#     df = pd.read_csv(\"/content/drive/MyDrive/SEM_3_Project/augmented_dataset.csv\")\n",
    "#     st.success(\"Default dataset loaded successfully!\")\n",
    "#     st.write(df.head())\n",
    "# except FileNotFoundError:\n",
    "#     st.warning(\"Default dataset not found! Please upload one below.\")\n",
    "\n",
    "# # Allow dataset upload\n",
    "# uploaded_file = st.file_uploader(\"Upload your email dataset (CSV)\", type=\"csv\")\n",
    "# if uploaded_file is not None:\n",
    "#     df = pd.read_csv(uploaded_file)\n",
    "#     st.success(\"Custom dataset uploaded successfully!\")\n",
    "#     st.write(df.head())\n",
    "\n",
    "# # ------------------------------\n",
    "# # Keyword Analysis\n",
    "# # ------------------------------\n",
    "# if df is not None and 'Email_Content' in df.columns:\n",
    "#     st.subheader(\"ðŸ” Phishing Keyword Frequency Analysis\")\n",
    "\n",
    "#     phishing_words = [\n",
    "#         \"verify\", \"account\", \"password\", \"urgent\", \"click\", \"update\",\n",
    "#         \"bank\", \"login\", \"secure\", \"alert\", \"confirm\", \"unsubscribe\", \"information\"\n",
    "#     ]\n",
    "#     freq = [df['Email_Content'].str.contains(word, case=False, na=False).sum() for word in phishing_words]\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(10, 5))\n",
    "#     ax.bar(phishing_words, freq)\n",
    "#     ax.set_title(\"Common Phishing-related Word Frequency\")\n",
    "#     ax.set_xlabel(\"Keywords\")\n",
    "#     ax.set_ylabel(\"Count\")\n",
    "#     st.pyplot(fig)\n",
    "# elif df is None:\n",
    "#     st.warning(\"Dataset not loaded. Cannot perform keyword analysis.\")\n",
    "# else:\n",
    "#     st.warning(\"Column 'Email_Content' not found in dataset.\")\n",
    "\n",
    "# # ------------------------------\n",
    "# # Model Loading\n",
    "# # ------------------------------\n",
    "# st.header(\"ðŸ§  Model Prediction\")\n",
    "\n",
    "# model_placeholder = \"/content/drive/MyDrive/SEM_3_Project/logistic_regression_model.pkl\"  # replace with your trained model name\n",
    "\n",
    "# try:\n",
    "#     model = joblib.load(model_placeholder)\n",
    "#     st.success(\"Model loaded successfully!\")\n",
    "# except:\n",
    "#     st.warning(\"No trained model found! Using a simple keyword-based rule instead.\")\n",
    "#     model = None\n",
    "\n",
    "# # ------------------------------\n",
    "# # Text Input Prediction\n",
    "# # ------------------------------\n",
    "# email_input = st.text_area(\"âœ‰ï¸ Enter email content to analyze:\")\n",
    "\n",
    "# def simple_predict(text):\n",
    "#     \"\"\"Basic keyword-based rule if ML model not loaded\"\"\"\n",
    "#     phishy_terms = [\"verify\", \"password\", \"urgent\", \"account\", \"click\", \"bank\", \"secure\"]\n",
    "#     matches = [w for w in phishy_terms if re.search(w, text, re.IGNORECASE)]\n",
    "#     return \"Phishing\" if len(matches) > 0 else \"Legitimate\"\n",
    "\n",
    "# #----------\n",
    "\n",
    "# def predict_email(email_content):\n",
    "#     if not model or not tfidf_vectorizer:\n",
    "#         return simple_predict(email_content)  # fallback to keyword rule\n",
    "\n",
    "#     try:\n",
    "#         # Step 1: Vectorize using trained TF-IDF model\n",
    "#         vectorized_input = tfidf_vectorizer.transform([email_content])\n",
    "\n",
    "#         # Step 2: Predict using the loaded model\n",
    "#         prediction = model.predict(vectorized_input.toarray())\n",
    "\n",
    "#         # Step 3: Return readable result\n",
    "#         return \"Phishing Email\" if prediction[0] == 1 else \"Safe Email\"\n",
    "\n",
    "#     except Exception as e:\n",
    "#         return f\"Error during model prediction: {e}\"\n",
    "\n",
    "\n",
    "# #----------\n",
    "\n",
    "\n",
    "\n",
    "# if st.button(\"ðŸ”Ž Predict\"):\n",
    "#     if email_input.strip() == \"\":\n",
    "#         st.warning(\"Please enter an email text.\")\n",
    "#     else:\n",
    "#         result = predict_email(email_input)\n",
    "#         st.success(f\"ðŸ§¾ Prediction: **{result}**\")\n",
    "\n",
    "#         st.info(\"Please ensure the input format matches the model's training data. If using TF-IDF or sequence padding, apply those transformations to the input text.\")\n",
    "\n",
    "# else:\n",
    "#             rule_pred = simple_predict(email_input)\n",
    "#             st.success(f\"ðŸ§¾ Prediction (Rule-based): **{rule_pred}**\")\n",
    "\n",
    "\n",
    "#             # ------------------------------\n",
    "# # TF-IDF Vectorizer Loading\n",
    "# # ------------------------------\n",
    "# tfidf_placeholder = \"/content/drive/MyDrive/SEM_3_Project/tfidf_vectorizer.pkl\"  # update path if needed\n",
    "\n",
    "# try:\n",
    "#     tfidf_vectorizer = joblib.load(tfidf_placeholder)\n",
    "#     st.success(\"TF-IDF vectorizer loaded successfully!\")\n",
    "# except:\n",
    "#     st.warning(\"TF-IDF vectorizer not found. Model may not work properly.\")\n",
    "#     tfidf_vectorizer = None\n",
    "\n",
    "\n",
    "# # ------------------------------\n",
    "# # Footer\n",
    "# # ------------------------------\n",
    "# st.markdown(\"---\")\n",
    "# st.caption(\"Developed by **Kaustubh Narayankar** | MSc Data Science | SIES College\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1759985228847,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "_ove0ZCdu5TX",
    "outputId": "2aaa9112-85e0-44a8-9f55-f06bc2c00c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "# # ===============================================\n",
    "# # app.py - Email Phishing Detection Streamlit App\n",
    "# # ===============================================\n",
    "# %%writefile app.py\n",
    "\n",
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import joblib\n",
    "# import re\n",
    "\n",
    "# # ------------------------------\n",
    "# # Page Configuration\n",
    "# # ------------------------------\n",
    "# st.set_page_config(page_title=\"Email Phishing Detection System\", layout=\"wide\")\n",
    "# st.title(\"ðŸ“§ Email Phishing Detection System\")\n",
    "# st.markdown(\"\"\"\n",
    "# This interactive app detects whether an email is **Phishing** or **Legitimate** based on its content.\n",
    "# It uses text analysis and machine learning for cybersecurity awareness and prevention.\n",
    "# \"\"\")\n",
    "\n",
    "# # ------------------------------\n",
    "# # Load Dataset\n",
    "# # ------------------------------\n",
    "# st.header(\"ðŸ“ Dataset Overview\")\n",
    "\n",
    "# df = None  # Initialize df to None\n",
    "# try:\n",
    "#     df = pd.read_csv(\"/content/drive/MyDrive/SEM_3_Project/augmented_dataset.csv\")\n",
    "#     st.success(\"Default dataset loaded successfully!\")\n",
    "#     st.write(df.head())\n",
    "# except FileNotFoundError:\n",
    "#     st.warning(\"Default dataset not found! Please upload one below.\")\n",
    "\n",
    "# uploaded_file = st.file_uploader(\"Upload your email dataset (CSV)\", type=\"csv\")\n",
    "# if uploaded_file is not None:\n",
    "#     df = pd.read_csv(uploaded_file)\n",
    "#     st.success(\"Custom dataset uploaded successfully!\")\n",
    "#     st.write(df.head())\n",
    "\n",
    "# # ------------------------------\n",
    "# # Keyword Analysis\n",
    "# # ------------------------------\n",
    "# if df is not None and 'Email_Content' in df.columns:\n",
    "#     st.subheader(\"ðŸ” Phishing Keyword Frequency Analysis\")\n",
    "\n",
    "#     phishing_words = [\n",
    "#         \"verify\", \"account\", \"password\", \"urgent\", \"click\", \"update\",\n",
    "#         \"bank\", \"login\", \"secure\", \"alert\", \"confirm\", \"unsubscribe\", \"information\"\n",
    "#     ]\n",
    "#     freq = [df['Email_Content'].str.contains(word, case=False, na=False).sum() for word in phishing_words]\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(10, 5))\n",
    "#     ax.bar(phishing_words, freq)\n",
    "#     ax.set_title(\"Common Phishing-related Word Frequency\")\n",
    "#     ax.set_xlabel(\"Keywords\")\n",
    "#     ax.set_ylabel(\"Count\")\n",
    "#     st.pyplot(fig)\n",
    "# elif df is None:\n",
    "#     st.warning(\"Dataset not loaded. Cannot perform keyword analysis.\")\n",
    "# else:\n",
    "#     st.warning(\"Column 'Email_Content' not found in dataset.\")\n",
    "\n",
    "# # ------------------------------\n",
    "# # Load Model and TF-IDF Vectorizer (move this ABOVE predict_email)\n",
    "# # ------------------------------\n",
    "# st.header(\"ðŸ§  Model Loading\")\n",
    "\n",
    "# model_path = \"/content/drive/MyDrive/SEM_3_Project/logistic_regression_model.pkl\"\n",
    "# tfidf_path = \"/content/drive/MyDrive/SEM_3_Project/tfidf_vectorizer.pkl\"\n",
    "\n",
    "# # Load model\n",
    "# try:\n",
    "#     model = joblib.load(model_path)\n",
    "#     st.success(\"âœ… Model loaded successfully!\")\n",
    "# except:\n",
    "#     st.error(\"âš ï¸ Could not load model. Please check the path or upload file.\")\n",
    "#     model = None\n",
    "\n",
    "# # Load TF-IDF vectorizer\n",
    "# try:\n",
    "#     tfidf_vectorizer = joblib.load(tfidf_path)\n",
    "#     st.success(\"âœ… TF-IDF Vectorizer loaded successfully!\")\n",
    "# except:\n",
    "#     st.error(\"âš ï¸ Could not load TF-IDF vectorizer. Please check the path or upload file.\")\n",
    "#     tfidf_vectorizer = None\n",
    "\n",
    "# # ------------------------------\n",
    "# # Prediction Functions\n",
    "# # ------------------------------\n",
    "# def simple_predict(text):\n",
    "#     \"\"\"Basic keyword-based rule if ML model not loaded\"\"\"\n",
    "#     phishy_terms = [\"verify\", \"password\", \"urgent\", \"account\", \"click\", \"bank\", \"secure\"]\n",
    "#     matches = [w for w in phishy_terms if re.search(w, text, re.IGNORECASE)]\n",
    "#     return \"Phishing\" if len(matches) > 0 else \"Legitimate\"\n",
    "\n",
    "# def predict_email(email_content):\n",
    "#     \"\"\"Predict using ML model or fallback to rule-based\"\"\"\n",
    "#     if model is None or tfidf_vectorizer is None:\n",
    "#         return simple_predict(email_content)\n",
    "\n",
    "#     try:\n",
    "#         # Step 1: Vectorize using trained TF-IDF model\n",
    "#         vectorized_input = tfidf_vectorizer.transform([email_content])\n",
    "\n",
    "#         # Step 2: Predict using the loaded model\n",
    "#         prediction = model.predict(vectorized_input)\n",
    "\n",
    "#         # Step 3: Return readable result\n",
    "#         return \"Phishing Email\" if prediction[0] == 1 else \"Safe Email\"\n",
    "\n",
    "#     except Exception as e:\n",
    "#         return f\"Error during model prediction: {e}\"\n",
    "\n",
    "# # ------------------------------\n",
    "# # Text Input & Prediction Section\n",
    "# # ------------------------------\n",
    "# st.header(\"âœ‰ï¸ Email Content Prediction\")\n",
    "\n",
    "# email_input = st.text_area(\"Enter email content to analyze:\")\n",
    "\n",
    "# if st.button(\"ðŸ”Ž Predict\"):\n",
    "#     if email_input.strip() == \"\":\n",
    "#         st.warning(\"Please enter an email text.\")\n",
    "#     else:\n",
    "#         result = predict_email(email_input)\n",
    "#         st.success(f\"ðŸ§¾ Prediction: **{result}**\")\n",
    "\n",
    "# # ------------------------------\n",
    "# # Footer\n",
    "# # ------------------------------\n",
    "# st.markdown(\"---\")\n",
    "# st.caption(\"Developed by **Kaustubh Narayankar** | MSc Data Science | SIES College\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyoHINZmUT42"
   },
   "source": [
    "# launch app BELOW\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awkgZSUpUaXD"
   },
   "source": [
    "\n",
    "\n",
    "*   app code 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WONd-LdluHK2"
   },
   "source": [
    "# RUN ONLY THIS APP (under development stage  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1760195988993,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "fz2sgHP5UeR3",
    "outputId": "e51054d0-7926-42ba-ef6a-ee87db282ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# app.py - Email Phishing Detection Streamlit App\n",
    "# ===============================================\n",
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# ------------------------------\n",
    "# Page Configuration\n",
    "# ------------------------------\n",
    "st.set_page_config(page_title=\"Email Phishing Detection System\", layout=\"wide\")\n",
    "st.title(\"ðŸ“§ Email Phishing Detection System\")\n",
    "st.markdown(\"\"\"\n",
    "This interactive app detects whether an email is **Phishing** or **Legitimate** based on its content.\n",
    "It uses text analysis and machine learning for cybersecurity awareness and prevention.\n",
    "\"\"\")\n",
    "\n",
    "# ------------------------------\n",
    "# Load Dataset\n",
    "# ------------------------------\n",
    "st.header(\"ðŸ“ Dataset Overview\")\n",
    "\n",
    "df = None  # Initialize df to None\n",
    "try:\n",
    "    df = pd.read_csv(\"/content/drive/MyDrive/SEM_3_Project/augmented_dataset.csv\")\n",
    "    st.success(\"Default dataset loaded successfully!\")\n",
    "    st.write(df.head())\n",
    "except FileNotFoundError:\n",
    "    st.warning(\"Default dataset not found! Please upload one below.\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload your email dataset (CSV)\", type=\"csv\")\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "    st.success(\"Custom dataset uploaded successfully!\")\n",
    "    st.write(df.head())\n",
    "\n",
    "# ------------------------------\n",
    "# Keyword Analysis\n",
    "# ------------------------------\n",
    "if df is not None and 'Email_Content' in df.columns:\n",
    "    st.subheader(\"ðŸ” Phishing Keyword Frequency Analysis\")\n",
    "\n",
    "    phishing_words = [\n",
    "        \"verify\", \"account\", \"password\", \"urgent\", \"click\", \"update\",\n",
    "        \"bank\", \"login\", \"secure\", \"alert\", \"confirm\", \"unsubscribe\", \"information\"\n",
    "    ]\n",
    "    freq = [df['Email_Content'].str.contains(word, case=False, na=False).sum() for word in phishing_words]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.bar(phishing_words, freq, color='teal')\n",
    "    ax.set_title(\"Common Phishing-related Word Frequency\")\n",
    "    ax.set_xlabel(\"Keywords\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    st.pyplot(fig)\n",
    "elif df is None:\n",
    "    st.warning(\"Dataset not loaded. Cannot perform keyword analysis.\")\n",
    "else:\n",
    "    st.warning(\"Column 'Email_Content' not found in dataset.\")\n",
    "\n",
    "# ------------------------------\n",
    "# Load Model and TF-IDF Vectorizer\n",
    "# ------------------------------\n",
    "st.header(\"ðŸ§  Model Loading\")\n",
    "\n",
    "model_path = \"/content/drive/MyDrive/SEM_3_Project/logistic_regression_model.pkl\"\n",
    "tfidf_path = \"/content/drive/MyDrive/SEM_3_Project/tfidf_vectorizer.pkl\"\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    model = joblib.load(model_path)\n",
    "    st.success(\"âœ… Model loaded successfully!\")\n",
    "except:\n",
    "    st.error(\"âš ï¸ Could not load model. Please check the path or upload file.\")\n",
    "    model = None\n",
    "\n",
    "# Load TF-IDF vectorizer\n",
    "try:\n",
    "    tfidf_vectorizer = joblib.load(tfidf_path)\n",
    "    st.success(\"âœ… TF-IDF Vectorizer loaded successfully!\")\n",
    "except:\n",
    "    st.error(\"âš ï¸ Could not load TF-IDF vectorizer. Please check the path or upload file.\")\n",
    "    tfidf_vectorizer = None\n",
    "\n",
    "# ------------------------------\n",
    "# Prediction Functions\n",
    "# ------------------------------\n",
    "def simple_predict(text):\n",
    "    \"\"\"Basic keyword-based rule if ML model not loaded\"\"\"\n",
    "    phishy_terms = [\"verify\", \"password\", \"urgent\", \"account\", \"click\", \"bank\", \"secure\"]\n",
    "    matches = [w for w in phishy_terms if re.search(w, text, re.IGNORECASE)]\n",
    "    return \"Phishing\" if len(matches) > 0 else \"Legitimate\"\n",
    "\n",
    "def predict_email(email_content):\n",
    "    \"\"\"Predict using ML model or fallback to rule-based\"\"\"\n",
    "    if model is None or tfidf_vectorizer is None:\n",
    "        return simple_predict(email_content)\n",
    "\n",
    "    try:\n",
    "        # Step 1: TF-IDF vectorization\n",
    "        tfidf_features = tfidf_vectorizer.transform([email_content])\n",
    "\n",
    "        # Step 2: Compute additional feature (spam word count)\n",
    "        spam_words = [\"win\", \"free\", \"prize\", \"offer\", \"money\", \"urgent\", \"lottery\", \"click\", \"account\"]\n",
    "        spam_count = sum(word in email_content.lower() for word in spam_words)\n",
    "        spam_feature = csr_matrix(np.array([[spam_count]]))\n",
    "\n",
    "        # Step 3: Combine TF-IDF + spam count (must match training dimension)\n",
    "        combined_features = hstack([tfidf_features, spam_feature])\n",
    "\n",
    "        # Step 4: Predict\n",
    "        prediction = model.predict(combined_features)\n",
    "        result = \"ðŸš¨ Phishing Email Detected\" if prediction[0] == 1 else \"âœ… Legitimate Email\"\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during model prediction: {e}\"\n",
    "\n",
    "# ------------------------------\n",
    "# Text Input & Prediction Section\n",
    "# ------------------------------\n",
    "st.header(\"âœ‰ï¸ Email Content Prediction\")\n",
    "\n",
    "email_input = st.text_area(\"Enter email content to analyze:\")\n",
    "\n",
    "if st.button(\"ðŸ”Ž Predict\"):\n",
    "    if email_input.strip() == \"\":\n",
    "        st.warning(\"Please enter an email text.\")\n",
    "    else:\n",
    "        result = predict_email(email_input)\n",
    "        st.success(f\"ðŸ§¾ Prediction: **{result}**\")\n",
    "\n",
    "# ------------------------------\n",
    "# Footer\n",
    "# ------------------------------\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"Developed by **Kaustubh Narayankar** | MSc Data Science | SIES College\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "executionInfo": {
     "elapsed": 10201,
     "status": "error",
     "timestamp": 1760196003010,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "-_sax7W4hsGo",
    "outputId": "7812472b-f043-47bb-ada9-2f513e275d2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pyngrok.process.ngrok:t=2025-10-11T15:20:04+0000 lvl=warn msg=\"failed to start tunnel\" pg=/api/tunnels id=0d9937f20339d032 err=\"failed to start tunnel: The endpoint 'https://untrapped-susann-semicontinuously.ngrok-free.dev' is already online. Either\\n1. stop your existing endpoint first, or\\n2. start both endpoints with `--pooling-enabled` to load balance between them.\\r\\n\\r\\nERR_NGROK_334\\r\\n\"\n"
     ]
    },
    {
     "ename": "PyngrokNgrokHTTPError",
     "evalue": "ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: The endpoint 'https://untrapped-susann-semicontinuously.ngrok-free.dev' is already online. Either\\n1. stop your existing endpoint first, or\\n2. start both endpoints with `--pooling-enabled` to load balance between them.\\r\\n\\r\\nERR_NGROK_334\\r\\n\"}}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 502: Bad Gateway",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1642699532.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Open fresh tunnel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ðŸš€ Streamlit app is live at:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m     tunnel = NgrokTunnel(api_request(f\"{api_url}/api/tunnels\", method=\"POST\", data=options,\n\u001b[0m\u001b[1;32m    392\u001b[0m                                      timeout=pyngrok_config.request_timeout),\n\u001b[1;32m    393\u001b[0m                          pyngrok_config, api_url)\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response {status_code}: {response_data.strip()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         raise PyngrokNgrokHTTPError(f\"ngrok client exception, API returned {status_code}: {response_data}\",\n\u001b[0m\u001b[1;32m    651\u001b[0m                                     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                                     status_code, e.reason, e.headers, response_data)\n",
      "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: The endpoint 'https://untrapped-susann-semicontinuously.ngrok-free.dev' is already online. Either\\n1. stop your existing endpoint first, or\\n2. start both endpoints with `--pooling-enabled` to load balance between them.\\r\\n\\r\\nERR_NGROK_334\\r\\n\"}}\n"
     ]
    }
   ],
   "source": [
    "import subprocess, time\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Start Streamlit again\n",
    "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\"])\n",
    "time.sleep(10)\n",
    "\n",
    "# Open fresh tunnel\n",
    "public_url = ngrok.connect(8501)\n",
    "print(\"ðŸš€ Streamlit app is live at:\", public_url.public_url)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNj4+MKLTICDkVDDVRjJRCL",
   "mount_file_id": "1mGkGY04pmZIbstlUJmQkLUi-1wuzXzjz",
   "provenance": [
    {
     "file_id": "1mGkGY04pmZIbstlUJmQkLUi-1wuzXzjz",
     "timestamp": 1759990759401
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
