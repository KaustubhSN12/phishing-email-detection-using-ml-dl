{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8R_kcH8vvMDu"
   },
   "source": [
    "##PART 1 DONT RUN\n",
    "\n",
    "---\n",
    "IF ERROR No module named 'pyngrok' THEN RUN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7618,
     "status": "ok",
     "timestamp": 1760678371013,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "O7b_zdznfmAx",
    "outputId": "64f683c4-83c3-4de9-9730-a3c9fce89370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
      "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.7.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
      "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyngrok-7.4.0-py3-none-any.whl (25 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyngrok, pydeck, streamlit\n",
      "Successfully installed pydeck-0.9.1 pyngrok-7.4.0 streamlit-1.50.0\n"
     ]
    }
   ],
   "source": [
    " !pip install streamlit pyngrok pandas matplotlib joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1760594292839,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "FNeG1mm1geXt"
   },
   "outputs": [],
   "source": [
    "# Runtime ‚Üí Restart runtime ‚Üí Yes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRlStUn0gBOH"
   },
   "source": [
    "#Streamlit\n",
    "\n",
    "https://dashboard.ngrok.com/get-started/your-authtoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWeLrugPhh8-"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "iF authentication failed: Usage of ngrok requires a verified account and authtoken ( THEN RUN THIS )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1760678380138,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "US_90tIzhiN9"
   },
   "outputs": [],
   "source": [
    "!pkill streamlit\n",
    "!pkill ngrok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1760678382664,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "x74V2vQ2hlYK"
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "ngrok.kill()  # ensures all tunnels are closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1527,
     "status": "ok",
     "timestamp": 1760678385896,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "3H0r05jonro-",
    "outputId": "4d22b52b-c87b-44c1-c489-d44a2778a2b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!ngrok config add-authtoken ''Your-Grok-APIKEY''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKRopZs8njle"
   },
   "source": [
    "##Colaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1760594293219,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "1HwLu6zif5hT"
   },
   "outputs": [],
   "source": [
    "# # ===============================================\n",
    "# # app.py - Email Phishing Detection Streamlit App\n",
    "# # ===============================================\n",
    "# %%writefile app.py\n",
    "# # your code here\n",
    "\n",
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import joblib\n",
    "# import re\n",
    "\n",
    "# # ------------------------------\n",
    "# # Page Configuration\n",
    "# # ------------------------------\n",
    "# st.set_page_config(page_title=\"Email Phishing Detection System\", layout=\"wide\")\n",
    "# st.title(\"üìß Email Phishing Detection System\")\n",
    "# st.markdown(\"\"\"\n",
    "# This interactive app detects whether an email is **Phishing** or **Legitimate** based on its content.\n",
    "# It uses text analysis and machine learning for cybersecurity awareness and prevention.\n",
    "# \"\"\")\n",
    "\n",
    "# # ------------------------------\n",
    "# # Load Dataset\n",
    "# # ------------------------------\n",
    "# st.header(\"üìÅ Dataset Overview\")\n",
    "\n",
    "# df = None # Initialize df to None\n",
    "# try:\n",
    "#     df = pd.read_csv(\"/content/drive/MyDrive/SEM_3_Project/augmented_dataset.csv\")\n",
    "#     st.success(\"Default dataset loaded successfully!\")\n",
    "#     st.write(df.head())\n",
    "# except FileNotFoundError:\n",
    "#     st.warning(\"Default dataset not found! Please upload one below.\")\n",
    "\n",
    "# # Allow dataset upload\n",
    "# uploaded_file = st.file_uploader(\"Upload your email dataset (CSV)\", type=\"csv\")\n",
    "# if uploaded_file is not None:\n",
    "#     df = pd.read_csv(uploaded_file)\n",
    "#     st.success(\"Custom dataset uploaded successfully!\")\n",
    "#     st.write(df.head())\n",
    "\n",
    "# # ------------------------------\n",
    "# # Keyword Analysis\n",
    "# # ------------------------------\n",
    "# if df is not None and 'Email_Content' in df.columns:\n",
    "#     st.subheader(\"üîç Phishing Keyword Frequency Analysis\")\n",
    "\n",
    "#     phishing_words = [\n",
    "#         \"verify\", \"account\", \"password\", \"urgent\", \"click\", \"update\",\n",
    "#         \"bank\", \"login\", \"secure\", \"alert\", \"confirm\", \"unsubscribe\", \"information\"\n",
    "#     ]\n",
    "#     freq = [df['Email_Content'].str.contains(word, case=False, na=False).sum() for word in phishing_words]\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(10, 5))\n",
    "#     ax.bar(phishing_words, freq)\n",
    "#     ax.set_title(\"Common Phishing-related Word Frequency\")\n",
    "#     ax.set_xlabel(\"Keywords\")\n",
    "#     ax.set_ylabel(\"Count\")\n",
    "#     st.pyplot(fig)\n",
    "# elif df is None:\n",
    "#     st.warning(\"Dataset not loaded. Cannot perform keyword analysis.\")\n",
    "# else:\n",
    "#     st.warning(\"Column 'Email_Content' not found in dataset.\")\n",
    "\n",
    "# # ------------------------------\n",
    "# # Model Loading\n",
    "# # ------------------------------\n",
    "# st.header(\"üß† Model Prediction\")\n",
    "\n",
    "# model_placeholder = \"/content/drive/MyDrive/SEM_3_Project/logistic_regression_model.pkl\"  # replace with your trained model name\n",
    "\n",
    "# try:\n",
    "#     model = joblib.load(model_placeholder)\n",
    "#     st.success(\"Model loaded successfully!\")\n",
    "# except:\n",
    "#     st.warning(\"No trained model found! Using a simple keyword-based rule instead.\")\n",
    "#     model = None\n",
    "\n",
    "# # ------------------------------\n",
    "# # Text Input Prediction\n",
    "# # ------------------------------\n",
    "# email_input = st.text_area(\"‚úâÔ∏è Enter email content to analyze:\")\n",
    "\n",
    "# def simple_predict(text):\n",
    "#     \"\"\"Basic keyword-based rule if ML model not loaded\"\"\"\n",
    "#     phishy_terms = [\"verify\", \"password\", \"urgent\", \"account\", \"click\", \"bank\", \"secure\"]\n",
    "#     matches = [w for w in phishy_terms if re.search(w, text, re.IGNORECASE)]\n",
    "#     return \"Phishing\" if len(matches) > 0 else \"Legitimate\"\n",
    "\n",
    "# #----------\n",
    "\n",
    "# def predict_email(email_content):\n",
    "#     if not model or not tfidf_vectorizer:\n",
    "#         return simple_predict(email_content)  # fallback to keyword rule\n",
    "\n",
    "#     try:\n",
    "#         # Step 1: Vectorize using trained TF-IDF model\n",
    "#         vectorized_input = tfidf_vectorizer.transform([email_content])\n",
    "\n",
    "#         # Step 2: Predict using the loaded model\n",
    "#         prediction = model.predict(vectorized_input.toarray())\n",
    "\n",
    "#         # Step 3: Return readable result\n",
    "#         return \"Phishing Email\" if prediction[0] == 1 else \"Safe Email\"\n",
    "\n",
    "#     except Exception as e:\n",
    "#         return f\"Error during model prediction: {e}\"\n",
    "\n",
    "\n",
    "# #----------\n",
    "\n",
    "\n",
    "\n",
    "# if st.button(\"üîé Predict\"):\n",
    "#     if email_input.strip() == \"\":\n",
    "#         st.warning(\"Please enter an email text.\")\n",
    "#     else:\n",
    "#         result = predict_email(email_input)\n",
    "#         st.success(f\"üßæ Prediction: **{result}**\")\n",
    "\n",
    "#         st.info(\"Please ensure the input format matches the model's training data. If using TF-IDF or sequence padding, apply those transformations to the input text.\")\n",
    "\n",
    "# else:\n",
    "#             rule_pred = simple_predict(email_input)\n",
    "#             st.success(f\"üßæ Prediction (Rule-based): **{rule_pred}**\")\n",
    "\n",
    "\n",
    "#             # ------------------------------\n",
    "# # TF-IDF Vectorizer Loading\n",
    "# # ------------------------------\n",
    "# tfidf_placeholder = \"/content/drive/MyDrive/SEM_3_Project/tfidf_vectorizer.pkl\"  # update path if needed\n",
    "\n",
    "# try:\n",
    "#     tfidf_vectorizer = joblib.load(tfidf_placeholder)\n",
    "#     st.success(\"TF-IDF vectorizer loaded successfully!\")\n",
    "# except:\n",
    "#     st.warning(\"TF-IDF vectorizer not found. Model may not work properly.\")\n",
    "#     tfidf_vectorizer = None\n",
    "\n",
    "\n",
    "# # ------------------------------\n",
    "# # Footer\n",
    "# # ------------------------------\n",
    "# st.markdown(\"---\")\n",
    "# st.caption(\"Developed by **Kaustubh Narayankar** | MSc Data Science | SIES College\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 704,
     "status": "aborted",
     "timestamp": 1760594293222,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "UzN8BHIbUW4t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyoHINZmUT42"
   },
   "source": [
    "\n",
    "\n",
    "*   app code 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1760594293234,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "_ove0ZCdu5TX"
   },
   "outputs": [],
   "source": [
    "# # ===============================================\n",
    "# # app.py - Email Phishing Detection Streamlit App\n",
    "# # ===============================================\n",
    "# %%writefile app.py\n",
    "\n",
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import joblib\n",
    "# import re\n",
    "\n",
    "# # ------------------------------\n",
    "# # Page Configuration\n",
    "# # ------------------------------\n",
    "# st.set_page_config(page_title=\"Email Phishing Detection System\", layout=\"wide\")\n",
    "# st.title(\"üìß Email Phishing Detection System\")\n",
    "# st.markdown(\"\"\"\n",
    "# This interactive app detects whether an email is **Phishing** or **Legitimate** based on its content.\n",
    "# It uses text analysis and machine learning for cybersecurity awareness and prevention.\n",
    "# \"\"\")\n",
    "\n",
    "# # ------------------------------\n",
    "# # Load Dataset\n",
    "# # ------------------------------\n",
    "# st.header(\"üìÅ Dataset Overview\")\n",
    "\n",
    "# df = None  # Initialize df to None\n",
    "# try:\n",
    "#     df = pd.read_csv(\"/content/drive/MyDrive/SEM_3_Project/augmented_dataset.csv\")\n",
    "#     st.success(\"Default dataset loaded successfully!\")\n",
    "#     st.write(df.head())\n",
    "# except FileNotFoundError:\n",
    "#     st.warning(\"Default dataset not found! Please upload one below.\")\n",
    "\n",
    "# uploaded_file = st.file_uploader(\"Upload your email dataset (CSV)\", type=\"csv\")\n",
    "# if uploaded_file is not None:\n",
    "#     df = pd.read_csv(uploaded_file)\n",
    "#     st.success(\"Custom dataset uploaded successfully!\")\n",
    "#     st.write(df.head())\n",
    "\n",
    "# # ------------------------------\n",
    "# # Keyword Analysis\n",
    "# # ------------------------------\n",
    "# if df is not None and 'Email_Content' in df.columns:\n",
    "#     st.subheader(\"üîç Phishing Keyword Frequency Analysis\")\n",
    "\n",
    "#     phishing_words = [\n",
    "#         \"verify\", \"account\", \"password\", \"urgent\", \"click\", \"update\",\n",
    "#         \"bank\", \"login\", \"secure\", \"alert\", \"confirm\", \"unsubscribe\", \"information\"\n",
    "#     ]\n",
    "#     freq = [df['Email_Content'].str.contains(word, case=False, na=False).sum() for word in phishing_words]\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(10, 5))\n",
    "#     ax.bar(phishing_words, freq)\n",
    "#     ax.set_title(\"Common Phishing-related Word Frequency\")\n",
    "#     ax.set_xlabel(\"Keywords\")\n",
    "#     ax.set_ylabel(\"Count\")\n",
    "#     st.pyplot(fig)\n",
    "# elif df is None:\n",
    "#     st.warning(\"Dataset not loaded. Cannot perform keyword analysis.\")\n",
    "# else:\n",
    "#     st.warning(\"Column 'Email_Content' not found in dataset.\")\n",
    "\n",
    "# # ------------------------------\n",
    "# # Load Model and TF-IDF Vectorizer (move this ABOVE predict_email)\n",
    "# # ------------------------------\n",
    "# st.header(\"üß† Model Loading\")\n",
    "\n",
    "# model_path = \"/content/drive/MyDrive/SEM_3_Project/logistic_regression_model.pkl\"\n",
    "# tfidf_path = \"/content/drive/MyDrive/SEM_3_Project/tfidf_vectorizer.pkl\"\n",
    "\n",
    "# # Load model\n",
    "# try:\n",
    "#     model = joblib.load(model_path)\n",
    "#     st.success(\"‚úÖ Model loaded successfully!\")\n",
    "# except:\n",
    "#     st.error(\"‚ö†Ô∏è Could not load model. Please check the path or upload file.\")\n",
    "#     model = None\n",
    "\n",
    "# # Load TF-IDF vectorizer\n",
    "# try:\n",
    "#     tfidf_vectorizer = joblib.load(tfidf_path)\n",
    "#     st.success(\"‚úÖ TF-IDF Vectorizer loaded successfully!\")\n",
    "# except:\n",
    "#     st.error(\"‚ö†Ô∏è Could not load TF-IDF vectorizer. Please check the path or upload file.\")\n",
    "#     tfidf_vectorizer = None\n",
    "\n",
    "# # ------------------------------\n",
    "# # Prediction Functions\n",
    "# # ------------------------------\n",
    "# def simple_predict(text):\n",
    "#     \"\"\"Basic keyword-based rule if ML model not loaded\"\"\"\n",
    "#     phishy_terms = [\"verify\", \"password\", \"urgent\", \"account\", \"click\", \"bank\", \"secure\"]\n",
    "#     matches = [w for w in phishy_terms if re.search(w, text, re.IGNORECASE)]\n",
    "#     return \"Phishing\" if len(matches) > 0 else \"Legitimate\"\n",
    "\n",
    "# def predict_email(email_content):\n",
    "#     \"\"\"Predict using ML model or fallback to rule-based\"\"\"\n",
    "#     if model is None or tfidf_vectorizer is None:\n",
    "#         return simple_predict(email_content)\n",
    "\n",
    "#     try:\n",
    "#         # Step 1: Vectorize using trained TF-IDF model\n",
    "#         vectorized_input = tfidf_vectorizer.transform([email_content])\n",
    "\n",
    "#         # Step 2: Predict using the loaded model\n",
    "#         prediction = model.predict(vectorized_input)\n",
    "\n",
    "#         # Step 3: Return readable result\n",
    "#         return \"Phishing Email\" if prediction[0] == 1 else \"Safe Email\"\n",
    "\n",
    "#     except Exception as e:\n",
    "#         return f\"Error during model prediction: {e}\"\n",
    "\n",
    "# # ------------------------------\n",
    "# # Text Input & Prediction Section\n",
    "# # ------------------------------\n",
    "# st.header(\"‚úâÔ∏è Email Content Prediction\")\n",
    "\n",
    "# email_input = st.text_area(\"Enter email content to analyze:\")\n",
    "\n",
    "# if st.button(\"üîé Predict\"):\n",
    "#     if email_input.strip() == \"\":\n",
    "#         st.warning(\"Please enter an email text.\")\n",
    "#     else:\n",
    "#         result = predict_email(email_input)\n",
    "#         st.success(f\"üßæ Prediction: **{result}**\")\n",
    "\n",
    "# # ------------------------------\n",
    "# # Footer\n",
    "# # ------------------------------\n",
    "# st.markdown(\"---\")\n",
    "# st.caption(\"Developed by **Kaustubh Narayankar** | MSc Data Science | SIES College\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DJ9OuG-vYkt"
   },
   "source": [
    "#LAUNCH THE APP BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awkgZSUpUaXD"
   },
   "source": [
    "\n",
    "\n",
    "*   app code 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1760678396011,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "fz2sgHP5UeR3",
    "outputId": "23a5e427-be48-416e-dd2b-a3a3048ee01e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# app.py - Email Phishing Detection Streamlit App\n",
    "# ===============================================\n",
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# ------------------------------\n",
    "# Page Configuration\n",
    "# ------------------------------\n",
    "st.set_page_config(page_title=\"Email Phishing Detection System\", layout=\"wide\")\n",
    "st.title(\"üìß Email Phishing Detection System\")\n",
    "st.markdown(\"\"\"\n",
    "This interactive app detects whether an email is **Phishing** or **Legitimate** based on its content.\n",
    "It uses text analysis and machine learning for cybersecurity awareness and prevention.\n",
    "\"\"\")\n",
    "\n",
    "# ------------------------------\n",
    "# Load Dataset\n",
    "# ------------------------------\n",
    "st.header(\"üìÅ Dataset Overview\")\n",
    "\n",
    "df = None  # Initialize df to None\n",
    "try:\n",
    "    df = pd.read_csv(\"/content/drive/MyDrive/SEM_3_Project/augmented_dataset.csv\")\n",
    "    st.success(\"Default dataset loaded successfully!\")\n",
    "    st.write(df.head())\n",
    "except FileNotFoundError:\n",
    "    st.warning(\"Default dataset not found! Please upload one below.\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload your email dataset (CSV)\", type=\"csv\")\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "    st.success(\"Custom dataset uploaded successfully!\")\n",
    "    st.write(df.head())\n",
    "\n",
    "# ------------------------------\n",
    "# Keyword Analysis\n",
    "# ------------------------------\n",
    "if df is not None and 'Email_Content' in df.columns:\n",
    "    st.subheader(\"üîç Phishing Keyword Frequency Analysis\")\n",
    "\n",
    "    phishing_words = [\n",
    "        \"verify\", \"account\", \"password\", \"urgent\", \"click\", \"update\",\n",
    "        \"bank\", \"login\", \"secure\", \"alert\", \"confirm\", \"unsubscribe\", \"information\"\n",
    "    ]\n",
    "    freq = [df['Email_Content'].str.contains(word, case=False, na=False).sum() for word in phishing_words]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.bar(phishing_words, freq, color='teal')\n",
    "    ax.set_title(\"Common Phishing-related Word Frequency\")\n",
    "    ax.set_xlabel(\"Keywords\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    st.pyplot(fig)\n",
    "elif df is None:\n",
    "    st.warning(\"Dataset not loaded. Cannot perform keyword analysis.\")\n",
    "else:\n",
    "    st.warning(\"Column 'Email_Content' not found in dataset.\")\n",
    "\n",
    "# ------------------------------\n",
    "# Load Model and TF-IDF Vectorizer\n",
    "# ------------------------------\n",
    "st.header(\"üß† Model Loading\")\n",
    "\n",
    "model_path = \"/content/drive/MyDrive/SEM_3_Project/logistic_regression_model.pkl\"\n",
    "tfidf_path = \"/content/drive/MyDrive/SEM_3_Project/tfidf_vectorizer.pkl\"\n",
    "#final_model = \"/content/drive/MyDrive/SEM_3_Project/final_model.pkl\"\n",
    "\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    model = joblib.load(model_path)\n",
    "    st.success(\"‚úÖ Model loaded successfully!\")\n",
    "except:\n",
    "    st.error(\"‚ö†Ô∏è Could not load model. Please check the path or upload file.\")\n",
    "    model = None\n",
    "\n",
    "# Load TF-IDF vectorizer\n",
    "try:\n",
    "    tfidf_vectorizer = joblib.load(tfidf_path)\n",
    "    st.success(\"‚úÖ TF-IDF Vectorizer loaded successfully! along with Bert\")\n",
    "except:\n",
    "    st.error(\"‚ö†Ô∏è Could not load TF-IDF vectorizer. Please check the path or upload file.\")\n",
    "    tfidf_vectorizer = None\n",
    "\n",
    "# ------------------------------\n",
    "# Prediction Functions\n",
    "# ------------------------------\n",
    "def simple_predict(text):\n",
    "    \"\"\"Basic keyword-based rule if ML model not loaded\"\"\"\n",
    "    phishy_terms = [\"verify\", \"password\", \"urgent\", \"account\", \"click\", \"bank\", \"secure\"]\n",
    "    matches = [w for w in phishy_terms if re.search(w, text, re.IGNORECASE)]\n",
    "    return \"Phishing\" if len(matches) > 0 else \"Legitimate\"\n",
    "\n",
    "def predict_email(email_content):\n",
    "    \"\"\"Predict using ML model or fallback to rule-based\"\"\"\n",
    "    if model is None or tfidf_vectorizer is None:\n",
    "        return simple_predict(email_content)\n",
    "\n",
    "    try:\n",
    "        # Step 1: TF-IDF vectorization\n",
    "        tfidf_features = tfidf_vectorizer.transform([email_content])\n",
    "\n",
    "        # Step 2: Compute additional feature (spam word count)\n",
    "        spam_words = [\"win\", \"free\", \"prize\", \"offer\", \"money\", \"urgent\", \"lottery\", \"click\", \"account\"]\n",
    "        spam_count = sum(word in email_content.lower() for word in spam_words)\n",
    "        spam_feature = csr_matrix(np.array([[spam_count]]))\n",
    "\n",
    "        # Step 3: Combine TF-IDF + spam count (must match training dimension)\n",
    "        combined_features = hstack([tfidf_features, spam_feature])\n",
    "\n",
    "        # Step 4: Predict\n",
    "        prediction = model.predict(combined_features)\n",
    "        result = \"üö® Phishing Email Detected\" if prediction[0] == 1 else \"‚úÖ Legitimate Email\"\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during model prediction: {e}\"\n",
    "\n",
    "# ------------------------------\n",
    "# Text Input & Prediction Section\n",
    "# ------------------------------\n",
    "st.header(\"‚úâÔ∏è Email Content Prediction\")\n",
    "\n",
    "email_input = st.text_area(\"Enter email content to analyze:\")\n",
    "\n",
    "if st.button(\"üîé Predict\"):\n",
    "    if email_input.strip() == \"\":\n",
    "        st.warning(\"Please enter an email text.\")\n",
    "    else:\n",
    "        result = predict_email(email_input)\n",
    "        st.success(f\"üßæ Prediction: **{result}**\")\n",
    "\n",
    "# ------------------------------\n",
    "# Footer\n",
    "# ------------------------------\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"Developed by **Kaustubh Narayankar** | MSc Data Science | SIES College\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10432,
     "status": "ok",
     "timestamp": 1760678410960,
     "user": {
      "displayName": "K.S.N",
      "userId": "07782968521927388551"
     },
     "user_tz": -330
    },
    "id": "-_sax7W4hsGo",
    "outputId": "6a7ca87a-6fdf-4ce9-c74a-337a28d90335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Streamlit app is live at: https://untrapped-susann-semicontinuously.ngrok-free.dev\n"
     ]
    }
   ],
   "source": [
    "import subprocess, time\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Start Streamlit again\n",
    "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\"])\n",
    "time.sleep(10)\n",
    "\n",
    "# Open fresh tunnel\n",
    "public_url = ngrok.connect(8501)\n",
    "print(\"üöÄ Streamlit app is live at:\", public_url.public_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXvzLaR4yIrz"
   },
   "source": [
    "# **Sample email dataset for testing** : [Email sample](https://docs.google.com/spreadsheets/d/1iyh37KJl67kJYSXl7Y2PciQKEHCEkIv74mf-JpPrDuI/edit?usp=drive_link)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNR0Uq1uFQjRWYKoFO+Jgq8",
   "mount_file_id": "1mGkGY04pmZIbstlUJmQkLUi-1wuzXzjz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
